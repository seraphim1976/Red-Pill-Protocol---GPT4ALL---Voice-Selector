# OpenAI Configuration (Required for Chat Bridge)
OPENAI_API_KEY=sk-your-openai-api-key-here
# OPENAI_BASE_URL=http://localhost:4891/v1
# LLM_MODEL_NAME=gpt-3.5-turbo  # Set this to your specific model if auto-detection fails (e.g., "Meta-Llama-3-8B-Instruct.Q4_0.gguf")

# Red Pill Protocol Configuration (v4.1.1)
# Copy this file to .env and adjust as needed.

# --- Qdrant Settings ---
QDRANT_MODE=embedded  # Options: "embedded" (default), "server"
QDRANT_HOST=localhost
QDRANT_PORT=6333
QDRANT_SCHEME=http
QDRANT_PATH=local_qdrant_db_v2
# [NEW v4.0.7] API Key for Qdrant (Optional but recommended for shared environments)
# QDRANT_API_KEY=your-secret-api-key

# --- Model Configuration ---
# FastEmbed model to use. changing this REQUIRES re-seeding!
EMBEDDING_MODEL=sentence-transformers/all-MiniLM-L6-v2
# [NEW v4.0.7] Vector dimensions. Must match the model.
VECTOR_SIZE=384

# --- B760-Adaptive Logic ---
# Decay Strategy: 'linear' (default) or 'exponential'
DECAY_STRATEGY=linear
# How much reinforcement score to subtract per erosion cycle
EROSION_RATE=0.05
# Score increment per search hit
REINFORCEMENT_INCREMENT=0.1
# How much score propagates to associated engrams (0.5 = 50% of increment)
PROPAGATION_FACTOR=0.5
# Score at which an engram becomes permanently immune to erosion
IMMUNITY_THRESHOLD=10.0
# [NEW v4.1.0] Triggers to automatically activate Deep Recall (comma-separated)
DEEP_RECALL_TRIGGERS="force recall,deep recall,try hard!"

# --- Logging ---
LOG_LEVEL=INFO
